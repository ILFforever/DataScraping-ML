{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c71aba7-c0f3-4378-9b63-55529e0994b4",
      "metadata": {
        "id": "1c71aba7-c0f3-4378-9b63-55529e0994b4"
      },
      "source": [
        "# Data\n",
        "\n",
        "We use the following dataset for fine-tuning:\n",
        "\n",
        "- [arXiv papers](https://www.kaggle.com/datasets/neelshah18/arxivdataset)\n",
        "\n",
        "The papers on arXiv also include papers on computational biology, genomics, etc.\n",
        "\n",
        "An alternative is the [dataset](https://zenodo.org/record/7695390) from [a recent study](https://www.biorxiv.org/content/10.1101/2023.04.10.536208v1.full.pdf) with titles and labels of papers from PubMed. It contains 20 million papers, but only titles are listed (no abstracts).\n",
        "\n",
        "In this notebook, we use data and tags from arXiv."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34471cf8",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e9874f4a-3898-4c89-a0f7-04eeabf2b389",
      "metadata": {
        "id": "e9874f4a-3898-4c89-a0f7-04eeabf2b389",
        "tags": []
      },
      "source": [
        "# Models\n",
        "\n",
        "We use BERT trained on biomedical data (from PubMed) as a base model.\n",
        "\n",
        "- [BiomedNLP-PubMedBERT](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "991e48e7-897f-45a3-8a0b-539ea67b4eb5",
      "metadata": {
        "id": "991e48e7-897f-45a3-8a0b-539ea67b4eb5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65282370",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2f130f05-21ee-46f9-889f-488e8c676aba",
      "metadata": {
        "id": "2f130f05-21ee-46f9-889f-488e8c676aba"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79e5433",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "757a0582-1b8c-4f1c-b26f-544688e391f4",
      "metadata": {
        "id": "757a0582-1b8c-4f1c-b26f-544688e391f4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "w:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, ClassLabel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import pipeline\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03847b87-d096-49a5-b6e2-023fa08b94c2",
      "metadata": {
        "id": "03847b87-d096-49a5-b6e2-023fa08b94c2"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e902ea-4e0f-4d76-b27b-59e472b2b556",
      "metadata": {
        "id": "b3e902ea-4e0f-4d76-b27b-59e472b2b556"
      },
      "source": [
        "Let's load the data for fine-tuning - in particular, we will need the titles of the articles, their abstracts and tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1be8f69e-bd7d-4ca9-ba9f-044b8e7bc497",
      "metadata": {
        "id": "1be8f69e-bd7d-4ca9-ba9f-044b8e7bc497",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PC02\\Desktop\\DataScrap\\AI_topic_recog\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "cur_dir = os.getcwd()\n",
        "print(cur_dir)\n",
        "df = pd.read_json(f\"{cur_dir}/output2.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791edb3c-a96d-4042-b35d-c8097bbbef79",
      "metadata": {
        "id": "791edb3c-a96d-4042-b35d-c8097bbbef79"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d5b6158a-728e-4ada-bcdc-a4a49328f002",
      "metadata": {
        "id": "d5b6158a-728e-4ada-bcdc-a4a49328f002"
      },
      "source": [
        "Let's combine the titles and abstracts and save the text in the appropriate column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c8709a7b-becf-4f19-8b4f-8773cd5c60f1",
      "metadata": {
        "id": "c8709a7b-becf-4f19-8b4f-8773cd5c60f1",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        Sparsity-certifying Graph Decompositions\\n  We...\n",
            "1        The evolution of the Earth-Moon system based o...\n",
            "2        A determinant of Stirling cycle numbers counts...\n",
            "3        From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...\n",
            "4        Bosonic characters of atomic Cooper pairs acro...\n",
            "                               ...                        \n",
            "41679    Deuteron production in p-Be interactions at 45...\n",
            "41680    Statistical relativistic temperature transform...\n",
            "41681    The time-dependent Born-Oppenheimer approximat...\n",
            "41682    The design of the time-of-flight system for MI...\n",
            "41683    Vortices in Quantum Rontgen Effect\\n  By the a...\n",
            "Name: text, Length: 41684, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df['text'] = df['title'] + \"\\n\" + df['abstract']\n",
        "print(df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed0ed687-6439-494a-a5a8-c572bc2e4059",
      "metadata": {
        "id": "ed0ed687-6439-494a-a5a8-c572bc2e4059",
        "outputId": "e15b2056-1a67-4eb5-8f07-183a86a07994",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>categories</th>\n",
              "      <th>abstract</th>\n",
              "      <th>update_date</th>\n",
              "      <th>authors_parsed</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704.0002</td>\n",
              "      <td>Ileana Streinu and Louis Theran</td>\n",
              "      <td>Sparsity-certifying Graph Decompositions</td>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "      <td>2008-12-13</td>\n",
              "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
              "      <td>Sparsity-certifying Graph Decompositions\\n  We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>704.0003</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>The evolution of the Earth-Moon system based o...</td>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "      <td>2008-01-13</td>\n",
              "      <td>[[Pan, Hongjun, ]]</td>\n",
              "      <td>The evolution of the Earth-Moon system based o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                          authors  \\\n",
              "0  704.0002  Ileana Streinu and Louis Theran   \n",
              "1  704.0003                      Hongjun Pan   \n",
              "\n",
              "                                               title      categories  \\\n",
              "0           Sparsity-certifying Graph Decompositions   math.CO cs.CG   \n",
              "1  The evolution of the Earth-Moon system based o...  physics.gen-ph   \n",
              "\n",
              "                                            abstract update_date  \\\n",
              "0    We describe a new algorithm, the $(k,\\ell)$-...  2008-12-13   \n",
              "1    The evolution of Earth-Moon system is descri...  2008-01-13   \n",
              "\n",
              "                             authors_parsed  \\\n",
              "0  [[Streinu, Ileana, ], [Theran, Louis, ]]   \n",
              "1                        [[Pan, Hongjun, ]]   \n",
              "\n",
              "                                                text  \n",
              "0  Sparsity-certifying Graph Decompositions\\n  We...  \n",
              "1  The evolution of the Earth-Moon system based o...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1de806-a4d2-4e58-a3a8-f3542392f22e",
      "metadata": {
        "id": "ce1de806-a4d2-4e58-a3a8-f3542392f22e"
      },
      "source": [
        "## Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5183517-8b02-47bc-812a-415b5651e07d",
      "metadata": {
        "id": "b5183517-8b02-47bc-812a-415b5651e07d"
      },
      "source": [
        "We will use categories from arXiv, such as `astro-ph` for astrophysics articles or `cs.CV` for computer vision (computer science)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ba4e7197-23b6-4cb4-9b44-620c6b730eb7",
      "metadata": {
        "id": "ba4e7197-23b6-4cb4-9b44-620c6b730eb7",
        "outputId": "bf76f720-bbf2-40af-eee6-3b0bec4662b2",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 133 labels such as astro-ph, cond-mat.dis-nn, ..., stat.ML\n"
          ]
        }
      ],
      "source": [
        "df['category'] = [i.split()[0].strip() for i in df['categories']]\n",
        "categories = np.unique(df['category'])\n",
        "num_labels = len(categories)\n",
        "print(f\"Total: {num_labels} labels such as {categories[0]}, {categories[1]}, ..., {categories[-1]}\")\n",
        "# df['category'] = [eval(i)[0]['term'].strip() for i in df['categories']]\n",
        "# categories = np.unique(df['category'])\n",
        "# num_labels = len(categories)\n",
        "# print(f\"Total: {num_labels} labels such as {categories[0]}, {categories[1]}, ..., {categories[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1508a6d9-856d-4ecf-a0f3-895d3ffbe99b",
      "metadata": {
        "id": "1508a6d9-856d-4ecf-a0f3-895d3ffbe99b",
        "outputId": "a2407802-de9d-4555-fa16-bc338652121e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>category_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>astro-ph</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cond-mat.dis-nn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cond-mat.mes-hall</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cond-mat.mtrl-sci</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cond-mat.other</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            category  category_index\n",
              "0           astro-ph               0\n",
              "1    cond-mat.dis-nn               1\n",
              "2  cond-mat.mes-hall               2\n",
              "3  cond-mat.mtrl-sci               3\n",
              "4     cond-mat.other               4"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\n",
        "    \"category\": categories,\n",
        "    \"category_index\": np.arange(num_labels),\n",
        "}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5c082c3a-7b0e-4320-b62d-f75a6c9f2398",
      "metadata": {
        "id": "5c082c3a-7b0e-4320-b62d-f75a6c9f2398",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"category\": categories,\n",
        "    \"category_index\": np.arange(num_labels),\n",
        "}).set_index(\"category\").join(df.set_index(\"category\"), how=\"right\", sort=False).reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d8ccb9-a993-4d82-9dd3-689380e92e55",
      "metadata": {
        "id": "76d8ccb9-a993-4d82-9dd3-689380e92e55"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a0c154f7-d2fa-46a1-8b69-57174bf00632",
      "metadata": {
        "id": "a0c154f7-d2fa-46a1-8b69-57174bf00632",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf6513d-664d-4b94-8b05-7e8df205e3ec",
      "metadata": {
        "id": "2bf6513d-664d-4b94-8b05-7e8df205e3ec"
      },
      "source": [
        "Tokenizer (name + abstract -> tokens):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "12fa49a7-2ac5-4f78-84fe-93305926692e",
      "metadata": {
        "id": "12fa49a7-2ac5-4f78-84fe-93305926692e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea1b4e5-9067-4292-ba12-8f560bbf26fd",
      "metadata": {
        "id": "0ea1b4e5-9067-4292-ba12-8f560bbf26fd"
      },
      "source": [
        "The model itself, in which `AutoModelForSequenceClassification` will replace the head for the classification task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d6eb92bc-c293-47ad-b9cc-2a63e8f1de69",
      "metadata": {
        "id": "d6eb92bc-c293-47ad-b9cc-2a63e8f1de69",
        "outputId": "9bb76b59-783e-48a8-90d3-0fe63e3ab3bf",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", num_labels=num_labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f5c79846-e6fc-42c0-bb8d-949678f5e60a",
      "metadata": {
        "id": "f5c79846-e6fc-42c0-bb8d-949678f5e60a",
        "outputId": "9ad1bf06-5b0a-464c-b096-775baea51de3",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=133, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce6eefc-91ce-4486-9568-b686d04adcc7",
      "metadata": {
        "id": "5ce6eefc-91ce-4486-9568-b686d04adcc7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71add72c-eafb-491a-8820-31ce7336524f",
      "metadata": {
        "id": "71add72c-eafb-491a-8820-31ce7336524f"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0b579c-998a-4d2e-bf0e-d4c7406d22da",
      "metadata": {
        "id": "2a0b579c-998a-4d2e-bf0e-d4c7406d22da"
      },
      "source": [
        "To work with `transformers`, it may be more convenient to use the `datasets` library for working with data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b0e14a-866b-49ac-8b95-49a91a0bcc22",
      "metadata": {
        "id": "47b0e14a-866b-49ac-8b95-49a91a0bcc22"
      },
      "source": [
        "Let's create (hugging face) [dataset](https://huggingface.co/docs/datasets/tabular_load#pandas-dataframes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dc1a3f33-0ef9-43c9-ab5f-eb9ae304b897",
      "metadata": {
        "id": "dc1a3f33-0ef9-43c9-ab5f-eb9ae304b897",
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "train_indices = np.sort(np.random.choice(np.arange(len(df)), size=37_000, replace=False))\n",
        "test_indices = np.array([i for i in np.arange(len(df)) if i not in train_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d948f8a6-1a7a-4baa-88a0-418596a1f275",
      "metadata": {
        "id": "d948f8a6-1a7a-4baa-88a0-418596a1f275",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df = df.loc[:,[\"text\", \"category\"]].iloc[train_indices]\n",
        "test_df = df.loc[:,[\"text\", \"category\"]].iloc[test_indices]\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df, split=\"train\")\n",
        "test_ds = Dataset.from_pandas(test_df, split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "50242a35-3067-41e5-8de8-f7e6a4fb6e9c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "50242a35-3067-41e5-8de8-f7e6a4fb6e9c",
        "outputId": "43aea52d-221d-4db5-af4a-7d9019830f8c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 37000/37000 [00:11<00:00, 3171.80 examples/s]\n",
            "Map: 100%|██████████| 4684/4684 [00:01<00:00, 3358.03 examples/s]\n"
          ]
        }
      ],
      "source": [
        "def tokenize_text(row):\n",
        "    return tokenizer(\n",
        "        row[\"text\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "    )\n",
        "\n",
        "train_ds = train_ds.map(tokenize_text, batched=True)\n",
        "test_ds = test_ds.map(tokenize_text, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "35d454d1-fbdc-4847-8b60-4c6c442364b1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "35d454d1-fbdc-4847-8b60-4c6c442364b1",
        "outputId": "9187a134-4730-4916-8cff-071a2e7fd5b9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 37000/37000 [00:00<00:00, 190685.32 examples/s]\n",
            "Map: 100%|██████████| 4684/4684 [00:00<00:00, 234189.06 examples/s]\n",
            "Casting the dataset: 100%|██████████| 37000/37000 [00:00<00:00, 331775.35 examples/s]\n",
            "Casting the dataset: 100%|██████████| 4684/4684 [00:00<00:00, 360340.42 examples/s]\n"
          ]
        }
      ],
      "source": [
        "labels_map = ClassLabel(num_classes=num_labels, names=list(categories))\n",
        "\n",
        "def transform_labels(row):\n",
        "    # default name for a label (label or label_ids)\n",
        "    return {\"label\": labels_map.str2int(row[\"category\"])}\n",
        "\n",
        "# OR:\n",
        "#\n",
        "# labels_map = pd.Series(\n",
        "#     np.arange(num_labels),\n",
        "#     index=categories,\n",
        "# )\n",
        "#\n",
        "# def transform_labels(row):\n",
        "#     return {\"label\": labels_map[row[\"category\"]]}\n",
        "\n",
        "train_ds = train_ds.map(transform_labels, batched=True)\n",
        "test_ds = test_ds.map(transform_labels, batched=True)\n",
        "\n",
        "train_ds = train_ds.cast_column('label', labels_map)\n",
        "test_ds = test_ds.cast_column('label', labels_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3862ef-ed78-461f-ba68-8f059f01d355",
      "metadata": {
        "id": "6f3862ef-ed78-461f-ba68-8f059f01d355"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "811c5fe3-218e-4187-878d-65abc157f802",
      "metadata": {
        "id": "811c5fe3-218e-4187-878d-65abc157f802"
      },
      "source": [
        "## Prepare training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d2160c7d-4130-47ae-9d6d-6684e4ba7e9b",
      "metadata": {
        "id": "d2160c7d-4130-47ae-9d6d-6684e4ba7e9b",
        "outputId": "86eea067-6254-450f-f78e-f99dc48abf7f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
        "    num_labels=num_labels,\n",
        "    id2label={i:labels_map.names[i] for i in range(len(categories))},\n",
        "    label2id={labels_map.names[i]:i for i in range(len(categories))},\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "72e74c2b-89d7-4c17-8df1-dcfd40ead01e",
      "metadata": {
        "id": "72e74c2b-89d7-4c17-8df1-dcfd40ead01e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb91037-fbdf-4453-87de-6da5eec3304f",
      "metadata": {
        "id": "ebb91037-fbdf-4453-87de-6da5eec3304f"
      },
      "source": [
        "Будем вычислять accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "630f6fa5-4c53-4962-b36d-5ee9aad6e29d",
      "metadata": {
        "id": "630f6fa5-4c53-4962-b36d-5ee9aad6e29d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f64425b7-72b7-466a-8e3e-cd7624893139",
      "metadata": {
        "id": "f64425b7-72b7-466a-8e3e-cd7624893139",
        "tags": []
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert-paper-classifier-arxiv\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b850cd9b-eb36-40ec-8cf2-26206fedcf27",
      "metadata": {
        "id": "b850cd9b-eb36-40ec-8cf2-26206fedcf27",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b88166-d82e-4502-acef-494fbb206d30",
      "metadata": {
        "id": "e6b88166-d82e-4502-acef-494fbb206d30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/5790 [02:40<258:42:49, 160.89s/it]"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 20.08 GiB is allocated by PyTorch, and 290.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\transformers\\trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2165\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2166\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2167\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2168\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2169\u001b[0m     )\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\transformers\\trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2520\u001b[0m )\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2528\u001b[0m ):\n\u001b[0;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\transformers\\trainer.py:3688\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3686\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3689\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\accelerate\\accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2248\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
            "File \u001b[1;32mw:\\Anaconda3\\envs\\DataScrap\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 20.08 GiB is allocated by PyTorch, and 290.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed8c94a-e3ef-47f9-96a8-c112eb7f11bc",
      "metadata": {
        "id": "7ed8c94a-e3ef-47f9-96a8-c112eb7f11bc"
      },
      "outputs": [],
      "source": [
        "# Convert to a python file and run training:\n",
        "#! jupyter nbconvert finetuning-arxiv.ipynb --to python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8dad7d-8105-4f37-9087-615314c35afb",
      "metadata": {
        "id": "cc8dad7d-8105-4f37-9087-615314c35afb"
      },
      "source": [
        "# Save and share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d24722-d5c6-40ac-b568-3cd7fd9f225e",
      "metadata": {
        "id": "38d24722-d5c6-40ac-b568-3cd7fd9f225e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.args.hub_model_id = \"bert-paper-classifier-arxiv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9530790c-bc63-48f4-9a01-8c534fa90e00",
      "metadata": {
        "id": "9530790c-bc63-48f4-9a01-8c534fa90e00",
        "outputId": "719a302f-299b-46fc-9e34-ee447f5ea4d4",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('bert-paper-classifier/tokenizer_config.json',\n",
              " 'bert-paper-classifier/special_tokens_map.json',\n",
              " 'bert-paper-classifier/vocab.txt',\n",
              " 'bert-paper-classifier/added_tokens.json',\n",
              " 'bert-paper-classifier/tokenizer.json')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"bert-paper-classifier-arxiv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0498df97-cd2c-4732-9d07-ee2013f8bd55",
      "metadata": {
        "id": "0498df97-cd2c-4732-9d07-ee2013f8bd55",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"bert-paper-classifier-arxiv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af12b9e-0d77-48ec-af6f-38556e13b067",
      "metadata": {
        "id": "7af12b9e-0d77-48ec-af6f-38556e13b067",
        "tags": []
      },
      "source": [
        "Запушим модель на HF Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de0e91f-bc23-4413-b22e-5aa32b09ef12",
      "metadata": {
        "id": "5de0e91f-bc23-4413-b22e-5aa32b09ef12",
        "outputId": "6772d5ea-601b-4ac7-daed-c1605d1d1bee",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://huggingface.co/oracat/bert-paper-classifier\n",
            "   915ccf0..862abb7  main -> main\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5093aee3-106e-43e9-a9c7-413d059ebb27",
      "metadata": {
        "id": "5093aee3-106e-43e9-a9c7-413d059ebb27"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b1a1029f-543c-409e-9aaf-35bcefe49988",
      "metadata": {
        "id": "b1a1029f-543c-409e-9aaf-35bcefe49988"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b0cd5a-2e17-49f3-b2a9-5ae4e8511969",
      "metadata": {
        "id": "e7b0cd5a-2e17-49f3-b2a9-5ae4e8511969"
      },
      "source": [
        "Теперь попробуем загрузить модель с HF Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fe37b9-61a9-4796-af24-092f6722cd61",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "36afc9d465f54c80ab01698f5a687388",
            "df18b9d22fc14a0c81e8cb557f88a848",
            "4ba2236cf89d4159bcc9740d4654b16d",
            "cae249ea1c2946a89fffdb80ff1d7b7b",
            "b860284eb1ff4cb08b5c8d54ab1a33b9",
            "3607b2b6f85b49b0a03844df69077d7e"
          ]
        },
        "id": "b7fe37b9-61a9-4796-af24-092f6722cd61",
        "outputId": "1dc7d304-2edb-4bf2-af84-45ccf991ee64",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36afc9d465f54c80ab01698f5a687388",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df18b9d22fc14a0c81e8cb557f88a848",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ba2236cf89d4159bcc9740d4654b16d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/679k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cae249ea1c2946a89fffdb80ff1d7b7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b860284eb1ff4cb08b5c8d54ab1a33b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3607b2b6f85b49b0a03844df69077d7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "inference_tokenizer = AutoTokenizer.from_pretrained(\"oracat/bert-paper-classifier-arxiv\")\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(\"oracat/bert-paper-classifier-arxiv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34495235-4dca-4635-b468-5b15647a6682",
      "metadata": {
        "id": "34495235-4dca-4635-b468-5b15647a6682",
        "tags": []
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", model=inference_model, tokenizer=inference_tokenizer, top_k=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052b5070-c1ee-4419-8a6d-127925c95cce",
      "metadata": {
        "id": "052b5070-c1ee-4419-8a6d-127925c95cce",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def top_pct(preds, threshold=.95):\n",
        "    preds = sorted(preds, key=lambda x: -x[\"score\"])\n",
        "\n",
        "    cum_score = 0\n",
        "    for i, item in enumerate(preds):\n",
        "        cum_score += item[\"score\"]\n",
        "        if cum_score >= threshold:\n",
        "            break\n",
        "\n",
        "    preds = preds[:(i+1)]\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3545b6-e043-4dfb-aeb2-7559eac37f7c",
      "metadata": {
        "id": "ed3545b6-e043-4dfb-aeb2-7559eac37f7c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def format_predictions(preds) -> str:\n",
        "    \"\"\"\n",
        "    Prepare predictions and their scores for printing to the user\n",
        "    \"\"\"\n",
        "    out = \"\"\n",
        "    for i, item in enumerate(preds):\n",
        "        out += f\"{i+1}. {item['label']} (score {item['score']:.2f})\\n\"\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870d593a-a298-4d55-87b0-cb2813cc1fad",
      "metadata": {
        "id": "870d593a-a298-4d55-87b0-cb2813cc1fad",
        "outputId": "277a81df-f06d-40c9-ce3e-6676e49e62f6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. cs.LG (score 0.88)\n",
            "2. cs.AI (score 0.07)\n",
            "3. cs.NE (score 0.03)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    format_predictions(\n",
        "        top_pct(\n",
        "            pipe(\"Attention Is All You Need\\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.\")[0]\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408f015e-be23-46a6-9e91-503fdccecf11",
      "metadata": {
        "id": "408f015e-be23-46a6-9e91-503fdccecf11"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DataScrap",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
